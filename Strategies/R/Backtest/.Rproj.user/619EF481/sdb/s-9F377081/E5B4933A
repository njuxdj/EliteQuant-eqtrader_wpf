{
    "contents" : "###-------------------------------- add Library Path -------------------------------###\n.libPaths( c(\"C:/Users/Letian/Documents/R/Library\",.libPaths()) )\nlibrary()\n## change work directory\ngetwd()\nsetwd(\"C:/QuantTrading/Strategies/R\")\n\n\n###-------------------------------- install package form zip -------------------------------###\n### install.packages('H:/R/Packages/zoo_1.7-9.zip', repos = NULL, type = 'source', lib='H:/R/Library')\n### library(zoo)\n### ls(\"package:zoo\", all = T)\n\n\n###-------------------------------- Data types -------------------------------###\ndata(trees)\nattach(trees)\n## + - * / %% (modulus), ^ (exponentiation)\n5%%2\n### 1. vectors\na <- c(1,2,5.3,6,-2,4)\t\t# numeric vector\nclass(a)\nunclass(a)\nstr(a)\nwhich (a^2>2)\t\t\t\t# find the index\nwhich(a == max(a))\nlength(a)\na[a > 4] <- 0\t\t\t# retrieve\na[c(2,4)]\t\t\t\t# 2nd and 4th elements of vector\nb <- c(\"one\",\"two\",\"three\")\t# character vector\nc <- c(TRUE, TRUE, FALSE, TRUE)\t# logical vector\nx <- rep(1,5)\ndiff(x)\nsign(x)\nseq(from = 1, to = 10, by = 2)\t\t# 1 3 5 7 9 sequence\nfor (i in seq(x))\t\t\t# use seq to avoid NULL case\nls()\nrm(list=ls())\n  \n### 2. Matrices\n### matrix multiplication %*%, transpose t(m)\ny <- matrix(1:20, nrow = 5, ncol = 4)\t\t# matrix by default is stored column-wise\ndim(y)\ny[,4]\t\t\t\t\t# 4th column of matrix\ny[,-3]\nm <- rbind( c(1,4), c(2,2) )\nA = matrix(c(3,1,1,2), nrow=2)\nB = solve(A); A%*%B\t\t# inverse\nt(A)   # transpose\nv = eigen(A)\t\t\t# eigen\nA%*%v$vectors[,1];  v$values[1]*v$vectors[,1] \t\t# first eigen, A*v = lambda*v\nsqrtA <- v$vectors %*% diag(sqrt(v$values)) %*% t(v$vectors)\t# square root of A\nsqrtA %*% sqrtA\t\t\t# it is A\n\n### 3. Data frames -- tables\n## constructed column-wise\nd <- c(1,2,3,4)\ne <- c(\"red\", \"white\", \"red\", NA)\nf <- c(TRUE, TRUE, FALSE, TRUE)\nmydata <- data.frame(d,e,f)\nnames(mydata) <- c(\"ID\", \"Color\", \"Passed\")\t\t# variable names\nmydata[2:3]\t\t# columns 2 and 3\nmydata[c(\"ID\",\"Passed\")]\nmydata$ID\n\n### 4. Lists -- struct\nw <- list(name=\"Fred\", mynumbers=a, mymatrix=y,age=5.3)\nw$name\t\t\t\t# retrieve\n\n### 5. Factors -- enum\ngender <- c(rep(\"male\",20), rep(\"female\",30))\ngender <- factor(gender)\nsummary(gender)\nincomes <- c( rep(2.5,20), rep(1.5,30) )\nincmean <- tapply(incomes, gender, mean)\n\n\n\n###-------------------------------- String and Date -------------------------------###\n## concatenate string\nu <- paste(\"abc\", \"de\", \"f\")\nstrsplit(u,\" \")\nv <- paste(\"abc\", \"de\", \"f\", sep=\"\")\n## change mode type\nz <- 0.9\ndigits <- as.character(z)\nd <- as.integer(digits)\nis.na(z)\n\n\n###-------------------------------- Flow control -------------------------------###\n## if ... else\nx = 0.5\nif (x > 0)  { y = sqrt(x) } else { y = -sqrt(-x) }\n## for loop; with keyword next and break\nx = rnorm(10); s = 0\nfor (i in 1:length(x)) { s = s+x[i] }\n## while\nx = 0\nwhile (x <= s) { x = x+1 }\n## function\nsquare = function(x) x*x\nsquare(1:10)\n## sqrt\nroot = function(x) {\n\trold = 0\n\trnew = 1\n\tfor (i in 1:10) {\n\t\tif (rnew == rold)\n\t\t\tbreak\n\t\trold = rnew\n\t\trnew = 0.5 * (rnew + x/rnew)\n\t}\n\trnew\n}\nroot(2)\n\n\n###-------------------------------- Apply Functions -------------------------------###\n### 1. apply -- applying a function to margins of an array or matrix\nm <- matrix(c(1:10, 11:20), nrow = 10, ncol = 2)\napply(m, 1, mean)\t\t\t# mean of the rows\napply(m, 2, mean)\t\t\t# mean of the columns\n## divide all values by 2, it equals m[,1:2]/2\napply(m, 1:2, function(x) x/2)\n\n### 2. lapply -- apply to list, return is also a list\n# create a list with 2 elements\nl <- list(a = 1:10, b = 11:20)\n# take mean and sum of the values in each element\nlapply(l, mean)\nlapply(l, sum)\n\n### 3. sapply -- apply to list, return vector instead of list\n# mean of values using sapply\nl.mean <- sapply(l, mean) \t\t\t# return a numeric vector\nl.mean[['a']]\n\n### 4. tapply -- apply to data frame according to factors\nattach(iris)\n# mean petal length by species\ntapply(iris$Petal.Length, Species, mean)\n\nstate <-c(\"NY\",\"NJ\",\"NJ\",\"NY\")\nstatef<-factor(state)\nlevels(statef)\nincomes<-c(100,200,50,70)\nincmeans<-tapply(incomes, statef,mean)\n\n\n### 5. rollapply -- rolling apply to time series\nz <- zoo(11:15, as.Date(31:35))\nrollapply(z, width = 3, mean, align=\"left\")\n\n### 6. cumsum, cumprod, cummin, cummax\ncumsum(1:10)\ncumprod(1:10)\n\n\n###-------------------------------- Filter Functions -------------------------------###\nma5 <- filter(spx.p, sides = 2, rep(1,5)/5)\n\n###-------------------------------- Optimization -------------------------------###\n### round, ceiling, floor\nround(1.5); round(1.49)\t\t\t# 2,1\nround(-1.5); round(-1.49)\t\t# -2, -1\nceiling(1.5); ceiling(-1.5)\t\t# 2, -1\nfloor(1.5); floor(-1.5)\t\t\t# 1, -2\n\n### optimize\nf <- function(x) {\n\tabs(x-3.5)+(x-2)^2\n}\nop <- optimize(f=f, interval = c(1,5))\n\n\n\n###-------------------------------- Simulation -------------------------------###\n### d: PDF\n### p: CDF\n### q: Inverse/quantile\n### r: Random\nx <- runif(10)\nmean(x); median(x); var(x); sd(x)\n### Draw sample\nsample(1:6, 10, replace = T)\t\t# roll a dice 10 times\nsample( c(\"H\",\"T\"), 10, replace = TRUE)\t# toss a coin\n### 1. Uniform\nx <- runif(100,0,2)\nhist(x, probability = TRUE, col = gray(.9), main = \"uniform on [0,2]\")\ncurve(dunif(x,0,2), add = T)\n\n### 2. Normal\nx <- rnorm(100, mean = 0, sd = 1)\nhist(x, probability = TRUE, main = \"normal mu = , sigma = 1\")\ncurve(dnorm(x), add = T)\n### Normal PDF\nx <- seq(from = -5, to = 5, by = 0.01)\ny <- dnorm(x)\nplot(x = x, y=y, type='l', col = \"seagreen\", lwd=2, \n\txlab=\"quantile\", ylab=\"density\\ny=dnorm(x)\")\ngrid(col=\"darkgrey\",lwd=2)\ntitle(main=\"Probability Density Function(PDF)\")\n### central limit theorem\nresults = c()\nmu = 0; sigma=1\nfor (i in 1:200) {\n\tX = rnorm(100, mu, sigma)\n\tresults[i] = (mean(X) - mu)/(sigma/sqrt(100))\n}\nhist(results, prob=T)\n## qq plot\nx <- rnorm(100,0,1)\nqqnorm(x, main = 'normal(0,1)')\nqqline(x)\n## empirical vs theretical density line\nx <- rnorm(1000, 5, 100)\nhist(x, prob+T, col = \"red\")\nlines(density(x), lwd=2)\nx <- seq(-4,4,length=100)\ny <- dnorm(x, mu,sigma)\nlines(x,y,lwd=2,col=\"blue\")\n## Normality test\nx <- rnorm(100, 5,9)\nshapiro.test(x)\nks.test(x,\"pnorm\", mean=mean(x),sd=sd(x))\nlibrary(\"tseries\")\njarque.bera.test(x)\n\n### 3. Binomial\nx <- rbinom(100, n, p)\nhist(x, prob=T)\nxvals <- 0:n\npoints(xvals, dbinom(xvals,n,p),type='h',lwd=3)\ny=(x-n*p)/sqrt(n*p*(1-p))\nhist(y,prob=T)\n\n### 4. Exponential\nx <- rexp(100,1/2500)\nhist(x,prob=T,col=gray(0.9), main=\"exponential mean=2500\")\ncurve(dexp(x,1/2500), add=T)\n\n\n\n###-------------------------------- ARIMA Time Series -------------------------------###\n### 1. White Noise\nw <- rnorm(1000)\nplot(w, type = \"l\")\nx <- seq(-3, 3, length=1000)\nhist(w,prob=T,breaks=10)\npoints(x,dnorm(x),type=\"l\")\nlines(density(x),col='red')\nacf(w)\n\n### 2. Random Walk\nx <- w <- rnorm(1000)\nfor (t in 2:1000) x[t] <- x[t-1]+w[t]\nplot(x, type=\"l\")\nacf(x)\npacf(x)\nacf(diff(x))\n\n### 3. AR(1)\nx <- w <- rnorm(1000)\nfor (t in 2:1000) x[t] <- 0.7*x[t-1]+w[t]\nplot(x, type = \"l\")\nacf(x)\npacf(x)\nx.ar <- ar(x, method = \"mle\")\n\n### 4. MA(3)\nb <- c(0.8,0.6,0.4)\nx <- w <- rnorm(1000)\nfor (t in 4:1000) {\n\tfor (j in 1:3) x[t] <- x[t] + b[j] * w[t-j]\n}\nplot(x, type=\"l\")\nacf(x)\npacf(x)\nx.ma <- arima(x,order=c(0,0,3))\n\n### 5. ARMA(1,1)\nx <- arima.sim(n=10000,list(ar=-0.6,ma=0.5))\nx.arma <- arima(x,order=c(1,0,1))\ncoef(x.arma)\nacf(resid(x.arma))\n\n### 6. ARIMA(1,1,1)\n# x_t = 0.5*x_t-1 +x_t-1 - 0.5*x_t-2 + w_t +0.3w_t-1\n# (1-B)(1-0.5B)x_t = (1-0.3B)w_t\nx <- w <- rnorm(10000)\nfor (i in 3:1000) x[i] <- 0.5*x[i-1] + x[i-1] - 0.5*x[i-2] + w[i] + 0.3*w[i-1]\narima(x,order=c(1,1,1))\nx <-arima.sim(mode=list(order=c(1,1,1), ar=0.5,ma=0.3), n=1000)\nx.arima <- arima(x,order=c(1,1,1))\ncoef(x.arima)\nAIC(x.arima)\npredict(x.arima,5)\n\n\n### 7. GARCH\nalpha0 <- 0.1\nalpha1 <- 0.4\nbeta1 <- 0.2\nw <- rnorm(10000)\na <- rep(0,10000)\nh <- rep(0,10000)\nfor (i in 2:10000) {\n\th[i] <- alpha0 + alpha1*(a[i-1]^2) + beta1*h[i-1]\n\ta[i] <- w[i]*sqrt(h[i])\n}\nplot(a, type=\"l\")\nacf(a)\nacf(a^2)\n## fit GARCH\nlibrary(tseries)\na.garch <- garch(a, grad = \"numerical\", trace = FALSE)\nconfint(a.garch)\n\n\n### 8. VAR(1)\nx <- y <- wx <- wy <- rnorm(1000)\nx[1] <- wx[1]\ny[1] <- wy[1]\nfor (i in 2:1000) {\n\tx[i] <- 0.4*x[i-1] + 0.3*y[i-1] + wx[i]\n\ty[i] <- 0.2*x[i-1] + 0.1*y[i-1] + wy[i]\n}\nxy.ar <- ar(cbind(x,y))\n\n### 9. Linear model x = 50 + 3*t + z\nz <- w <- rnorm(1000, sd=20)\nfor (t in 2:1000) z[t] <- 0.8*z[t-1]+w[t]\nTime <-1:1000\nx <- 50 + 3*Time +z\nplot(x, xlab=\"time\", type=\"l\")\nx.lm <- lm(x~Time)\ncoef(x.lm)\nsqrt(diag(vcov(x.lm)))\nsummary(x.lm)\n# with autocorrelation in the residuals, OLS is not accurate\nacf(resid(x.lm))\npacf(resid(x.lm))\n## For a positive serial correlation in the residual series,\n## the standard errors of the estimated regression parameters are likely to be underestimated.\n### Generalized least square (GLS) can account for autocorrelation in the residual series.\nlibrary(nlme)\nx.gls <- gls( x~Time, cor = corAR1(0.8 ))\ncoef(x.gls)\nsqrt(diag(vcov(x.gls)))\nconfint(x.gls)\n\n### 10. GBM\n# dlnS = (mu-0.5sigma^2)dt+sigmadW\nmu <- 0\nsigma <- 0.3\nT <- 4\nS0 <- 100\nw <- rnorm(250*4,sd=1/sqrt(250))\nt <- seq(0,4,by=1/250)\ndlns <- (mu+0.5*sigma^2)*1/250+sigma*w\nlns<-cumsum(dlns)+log(S0)\nS <- c(S0,exp(lns))\nplot(t,S,type='l')\nES <- S0*exp(mu*t)\nlines(t,ES,col='red')\n\n###-------------------------------- State Space Models -------------------------------###\n\n\n###-------------------------------- I/O -------------------------------###\nx <- read.table(\"c:/x.txt\", header=TRUE, sep=\",\")\nx <- read.csv(\"c:x.csv\", header=TRUE)\ncolnames(x) <- c(\"date\",\"price\",\"volumn\")      # give column names\nwrite(x=m,file=\"matrix.dat\",sep=\"\\t\",row.names=F,col.names=F)\n",
    "created" : 1415668540138.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1137402268",
    "id" : "E5B4933A",
    "lastKnownWriteTime" : 1413694457,
    "path" : "C:/QuantTrading/Strategies/R/Basics.R",
    "project_path" : null,
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}